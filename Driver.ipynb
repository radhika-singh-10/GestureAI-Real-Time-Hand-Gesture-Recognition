{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the CSV Files Without Any Empty Directory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('./20bn-jester-v1/annotations/jester-v1-validation.csv', delimiter=';', header=None)\n",
    "\n",
    "\n",
    "classes_to_select = ['Swiping Left', 'Swiping Right', 'Swiping Down', 'Swiping Up', 'Doing other things']  \n",
    "class_column = 1 \n",
    "filtered_data = data[data[class_column].isin(classes_to_select)]\n",
    "\n",
    "\n",
    "print(filtered_data)\n",
    "\n",
    "\n",
    "print(filtered_data.shape)\n",
    "filtered_data.to_csv('5_class_validation_data.csv',header=False,index=False,sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./CVND---Gesture-Recognition/20bn-jester-v1/annotations/5_class_training_data.csv\")\n",
    "print(data.shape)\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "root_folder = \"./CVND---Gesture-Recognition/data2/20bn-jester-v1\"\n",
    "\n",
    "def check_empty_folders(root):\n",
    "    empty_folders = []\n",
    "    for dirpath, dirnames, filenames in os.walk(root):\n",
    "        for dirname in dirnames:\n",
    "            folder_path = os.path.join(dirpath, dirname)\n",
    "            if not os.listdir(folder_path):\n",
    "                print(f\"The folder '{folder_path}' is empty.\")\n",
    "                empty_folders.append(dirname) \n",
    "            else:\n",
    "               \n",
    "                continue\n",
    "    return empty_folders\n",
    "\n",
    "empty_folders_list = check_empty_folders(root_folder)\n",
    "print(\"Empty folders:\", empty_folders_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle_file = \"empty_folders_list.pickle\"\n",
    "with open(pickle_file, 'wb') as f:\n",
    "    pickle.dump(empty_folders_list, f)\n",
    "\n",
    "print(f\"Empty folders list saved to '{pickle_file}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle_file_path = \"./CVND---Gesture-Recognition/empty_folders_list.pickle\"\n",
    "with open(pickle_file_path, 'rb') as f:\n",
    "    empty_folders_list = pickle.load(f)\n",
    "print(\"Empty folders list:\", empty_folders_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_folders_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = './20bn-jester-v1/annotations/5_class_training_data.csv'\n",
    "df = pd.read_csv(csv_path, header=None,delimiter=';')\n",
    "filtered_df = df[~df[0].isin(empty_folders_list)]\n",
    "filtered_csv_path = '5_class_training_data_filtered.csv'\n",
    "filtered_df.to_csv(filtered_csv_path, index=False, header=False,sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = './20bn-jester-v1/annotations/5_class_validation_data.csv'\n",
    "df = pd.read_csv(csv_path, header=None,delimiter=';')\n",
    "filtered_df = df[~df[0].isin(empty_folders_list)]\n",
    "filtered_csv_path = '5_class_valid_data_filtered.csv'\n",
    "filtered_df.to_csv(filtered_csv_path, index=False, header=False,sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "with open('your_empty_folders_list_path.pickle', 'rb') as file:\n",
    "    empty_folders_list = pickle.load(file)\n",
    "df = pd.read_csv('./20bn-jester-v1/annotations/5classvalid10000.csv', header=None, sep=';')\n",
    "df[0] = df[0].astype(str) \n",
    "filtered_df = df[~df[0].isin(empty_folders_list)]\n",
    "filtered_df.to_csv('filtered_val_data.csv', index=False, header=False, sep=';')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inferencing video on trained model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 test.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: FFMPEG: tag 0x44495658/'XVID' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video saved at /Users/atharvamusale/Downloads/DL_Project/output_video.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-28 15:25:44.190 Python[39477:6301460] WARNING: Secure coding is not enabled for restorable state! Enable secure coding by implementing NSApplicationDelegate.applicationSupportsSecureRestorableState: and returning YES.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video with predictions saved to: /Users/atharvamusale/Downloads/DL_Project/output_predictions_video.mp4\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import cv2\n",
    "from torchvision.transforms import Compose, CenterCrop, ToTensor, Normalize\n",
    "from model import GestureDetection\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "image_folder = './CVND---Gesture-Recognition/data2/20bn-jester-v1/60971'\n",
    "\n",
    "video_path = './output_video.mp4'\n",
    "\n",
    "frame_width = 1920  \n",
    "frame_height = 1080 \n",
    "fps = 30  \n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter(video_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "\n",
    "files = [os.path.join(image_folder, f) for f in os.listdir(image_folder) if os.path.isfile(os.path.join(image_folder, f))]\n",
    "files.sort()\n",
    "\n",
    "\n",
    "for filename in files:\n",
    "    img = cv2.imread(filename)\n",
    "    if img is None:\n",
    "        continue  \n",
    "    img = cv2.resize(img, (frame_width, frame_height))  \n",
    "    out.write(img) \n",
    "\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(f'Video saved at {video_path}')\n",
    "\n",
    "label_mapping_path = './20bn-jester-v1/annotations/jester-v1-labels-quick-testing copy.csv'\n",
    "\n",
    "\n",
    "def load_label_mapping(label_mapping_path):\n",
    "    label_mapping = {}\n",
    "    with open(label_mapping_path, 'r') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            label = line.strip()\n",
    "            label_mapping[i] = label\n",
    "    return label_mapping\n",
    "\n",
    "label_mapping = load_label_mapping(label_mapping_path)\n",
    "\n",
    "\n",
    "def preprocess_frames(frames, transform):\n",
    "    processed_frames = [transform(Image.fromarray(frame)) for frame in frames]\n",
    "    frame_stack = torch.stack(processed_frames, dim=1)\n",
    "    return frame_stack.unsqueeze(0)\n",
    "\n",
    "\n",
    "model = GestureDetection(num_classes=7)\n",
    "\n",
    "checkpoint = torch.load('./trainings/jpeg_model/7_classes/v17/checkpoint.pth.tar', map_location='cpu')\n",
    "state_dict = checkpoint['state_dict'] if 'state_dict' in checkpoint else checkpoint\n",
    "\n",
    "\n",
    "new_state_dict = {}\n",
    "for k, v in state_dict.items():\n",
    "    name = k[7:] if k.startswith('module.') else k \n",
    "    new_state_dict[name] = v\n",
    "\n",
    "model.load_state_dict(new_state_dict, strict=False)\n",
    "model.eval()\n",
    "\n",
    "\n",
    "transform = Compose([\n",
    "    CenterCrop(84),\n",
    "    ToTensor(),\n",
    "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "\n",
    "def load_label_mapping(label_mapping_path):\n",
    "    label_mapping = {}\n",
    "    with open(label_mapping_path, 'r') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            label = line.strip()\n",
    "            label_mapping[i] = label\n",
    "    return label_mapping\n",
    "\n",
    "label_mapping = load_label_mapping('./20bn-jester-v1/annotations/jester-v1-labels-quick-testing copy.csv')\n",
    "\n",
    "video_path = './output_video.mp4'\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "frame_sequence = []\n",
    "sequence_length = 16\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v') \n",
    "out_video_path = './output_predictions_video.mp4'\n",
    "out = cv2.VideoWriter(out_video_path, fourcc, cap.get(cv2.CAP_PROP_FPS), (int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))))\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    if len(frame_sequence) < sequence_length:\n",
    "        frame_sequence.append(frame_rgb)\n",
    "        continue\n",
    "    else:\n",
    "        frame_sequence.pop(0)\n",
    "        frame_sequence.append(frame_rgb)\n",
    "\n",
    "\n",
    "    frame_processed = preprocess_frames(frame_sequence, transform)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(frame_processed)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    predicted_gesture = label_mapping[predicted.item()]\n",
    "\n",
    "    cv2.putText(frame, predicted_gesture, (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "    cv2.imshow('Video - Gesture Recognition', frame)\n",
    "    out.write(frame) \n",
    "\n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(\"Video with predictions saved to:\", out_video_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.0.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
